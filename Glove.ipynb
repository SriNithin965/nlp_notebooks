{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriNithin965/nlp_notebooks/blob/main/Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GLOVE\n",
        "\n",
        "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space."
      ],
      "metadata": {
        "id": "xf-yoNawt9Fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the pacakages"
      ],
      "metadata": {
        "id": "VIayYfDPtV09"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SZlFKPPpAyK"
      },
      "source": [
        " import os\n",
        " import urllib.request\n",
        " from scipy import spatial\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the glove model"
      ],
      "metadata": {
        "id": "j1bzWhr8taGf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcegp2w2rOt0",
        "outputId": "1d360d0e-c4cd-4e0a-ea5e-a005c6db51db"
      },
      "source": [
        "urllib.request.urlretrieve('https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('glove.6B.zip', <http.client.HTTPMessage at 0x7f5cc5a9b1d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzipping the model"
      ],
      "metadata": {
        "id": "mLrqylF_tej_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH1jhhLCr80A",
        "outputId": "79ed082d-9751-4948-fdfb-e125a235b2e2"
      },
      "source": [
        "!unzip \"/content/glove.6B.zip\" -d \"/content/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/glove.6B.50d.txt  \n",
            "  inflating: /content/glove.6B.100d.txt  \n",
            "  inflating: /content/glove.6B.200d.txt  \n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the words and vectors from the  model making as dictionary"
      ],
      "metadata": {
        "id": "6LTW1UjBthrp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3hQeiRmuUey"
      },
      "source": [
        "emmbed_dict = {}\n",
        "with open('/content/glove.6B.200d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vectorization of india "
      ],
      "metadata": {
        "id": "ilIAGslHtrSm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8Z_SZ7alEx",
        "outputId": "a505fc54-4029-4162-b9e0-e663e8157d9f"
      },
      "source": [
        "emmbed_dict['india']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.0372e-01,  6.3592e-01, -4.9522e-02,  8.0130e-02, -2.3837e-01,\n",
              "        1.6099e-01,  4.0911e-01,  1.0195e-02, -3.8136e-02, -1.1211e-01,\n",
              "       -1.5057e-01,  1.0014e+00, -5.1784e-01,  1.1428e-01, -2.5988e-01,\n",
              "       -1.2952e-01, -3.8066e-01,  5.6304e-01, -2.0361e-01,  4.2629e-01,\n",
              "        3.1651e-03,  3.2066e+00, -1.4814e-01,  1.9738e-01,  6.0954e-01,\n",
              "       -2.0487e-01, -1.6529e-01,  1.5731e+00,  8.1018e-01,  5.4659e-03,\n",
              "        4.4647e-01, -1.1974e+00, -1.6670e-01, -3.4957e-02, -2.3592e-01,\n",
              "        1.9449e-01, -3.0062e-01, -4.7871e-01, -5.4198e-02, -9.3299e-02,\n",
              "       -3.4409e-01, -2.9381e-01,  2.5181e-01,  6.3102e-01, -7.2367e-01,\n",
              "       -3.8043e-01, -8.7755e-02, -4.3951e-01, -1.7207e-01, -5.2170e-01,\n",
              "       -2.4400e-01, -4.4542e-02, -1.6838e-01, -2.6438e-01, -1.7562e-01,\n",
              "       -3.3746e-01, -3.8011e-01,  1.1634e-01,  3.5150e-01,  1.9324e-01,\n",
              "       -7.1287e-01,  5.4914e-01, -1.6859e-01,  3.2083e-01,  8.4012e-01,\n",
              "        2.3606e-02, -3.6049e-01, -1.6917e-01,  2.1749e-02, -8.3271e-01,\n",
              "       -2.6476e-01, -5.8098e-01, -8.4177e-01,  9.0855e-01, -8.8447e-01,\n",
              "        6.2128e-01,  3.3015e-01,  2.4048e-01, -3.1179e-01, -2.6093e-02,\n",
              "        9.9930e-02,  1.7869e-01, -7.5065e-01,  3.8359e-01,  3.2446e-01,\n",
              "       -3.1412e-02, -8.7693e-02, -2.5653e-01,  3.5572e-01,  5.5505e-01,\n",
              "       -6.3830e-01, -1.0760e-01, -2.1922e-01, -1.1987e+00, -7.6799e-01,\n",
              "       -4.5337e-01, -1.7870e-01, -2.6280e-01,  5.8932e-01, -1.9539e-01,\n",
              "        6.3909e-01,  5.2982e-01,  1.6076e-01,  4.0558e-01, -2.9594e-01,\n",
              "        2.0216e-01,  6.7106e-03,  3.2270e-01,  1.5105e-01, -1.6511e-01,\n",
              "       -7.5351e-01, -9.5208e-01, -1.6975e-01, -1.2012e-01, -3.3244e-01,\n",
              "        5.7209e-01,  3.2610e-01,  4.6840e-01, -4.9835e-01, -2.6977e-01,\n",
              "       -8.8386e-03,  4.4159e-01, -1.9490e-01,  6.6333e-01,  4.9532e-01,\n",
              "       -1.8726e-01, -4.7090e-01, -1.3573e-01,  1.5765e-02, -3.9402e-01,\n",
              "        2.4640e-01,  5.2535e-01, -6.8423e-01,  1.6882e-01, -2.3455e-01,\n",
              "        2.3791e-01, -1.6323e-01,  1.3812e-01,  1.0544e-01, -4.5747e-01,\n",
              "        5.7875e-02, -6.6852e-01,  6.6011e-02, -9.0329e-02,  1.0341e+00,\n",
              "       -1.4296e-01, -3.7009e-01,  3.9010e-01,  7.9722e-02, -2.4370e-01,\n",
              "        3.2992e-01, -4.3281e-01,  1.9374e-01,  9.7304e-02,  4.2588e-01,\n",
              "        1.4239e-01, -1.3104e-01, -3.1096e-02, -3.1748e-01, -6.1463e-01,\n",
              "       -2.7041e-01, -2.7942e-01,  6.0646e-02,  3.9452e-01,  3.6715e-01,\n",
              "        2.9296e-01,  1.9578e-01, -7.6442e-01, -1.8261e-01,  3.5980e-01,\n",
              "        2.2200e-01,  1.5049e-01,  1.3977e-01, -8.1448e-03, -3.9114e-02,\n",
              "        3.9332e-01, -1.2253e-01,  4.6466e-01,  2.4893e-01, -3.2011e-01,\n",
              "        1.0340e+00,  2.9634e-02,  4.3713e-01,  8.7066e-01, -6.0383e-01,\n",
              "        3.1843e-01, -6.6131e-01,  5.6136e-01, -1.9788e-01, -3.0963e-01,\n",
              "       -3.9618e-01,  2.1651e-01,  1.0276e-02, -1.8712e-01,  5.5347e-01,\n",
              "        7.4848e-01,  1.6399e-01, -4.9797e-01, -9.2890e-03,  2.1040e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fucntion that tells the similar words"
      ],
      "metadata": {
        "id": "4HI_rk8stxSm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQeeYvOFvpmW"
      },
      "source": [
        "def find_similar_word(emmbedes):\n",
        "  nearest = sorted(emmbed_dict.keys(), key=lambda word: spatial.distance.euclidean(emmbed_dict[word], emmbedes))\n",
        "  return nearest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO_XEvSJdOHs",
        "outputId": "f5c7d851-84fa-4a10-a76c-2ac032e7b6e3"
      },
      "source": [
        "find_similar_word(emmbed_dict['river'])[0:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['river',\n",
              " 'rivers',\n",
              " 'tributary',\n",
              " 'confluence',\n",
              " 'creek',\n",
              " 'along',\n",
              " 'tributaries',\n",
              " 'valley',\n",
              " 'flows',\n",
              " 'danube']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roCgWYTxDteB",
        "outputId": "f621040a-f7f9-4c08-ded0-e87443f098f7"
      },
      "source": [
        "find_similar_word(emmbed_dict['king'] + emmbed_dict['queen'] + emmbed_dict['prince'])[0:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king',\n",
              " 'prince',\n",
              " 'queen',\n",
              " 'princess',\n",
              " 'crown',\n",
              " 'throne',\n",
              " 'royal',\n",
              " 'monarch',\n",
              " 'kingdom',\n",
              " 'duke']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}