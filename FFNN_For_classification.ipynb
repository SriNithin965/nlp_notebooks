{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLV1Lwr6hX0jyX3uQ7aNuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriNithin965/nlp_notebooks/blob/main/FFNN_For_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classification\n",
        "classification is the problem where the model classifies the input as one class in the multiple classes \n",
        "\n",
        "we are gonna implement the classification using feedforward neural networks\n",
        "the dataset we using is breats cancer with two classes as output\n",
        "\n",
        "the sigmoid fuction helps use to allocate the precentage of input which belongs to which class"
      ],
      "metadata": {
        "id": "uZBdKhjdYc2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FFNN using the pytorch"
      ],
      "metadata": {
        "id": "BgtVEOpbZI6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flFGhJJJWfSB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "      \n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model building\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) model training\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# model evaluation\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: ',acc.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FFNN using keras"
      ],
      "metadata": {
        "id": "b-Hk1s5gZuw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 1) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "y_train = y_train.reshape(y_train.shape[0],1)\n",
        "y_test = y_test.reshape(y_test.shape[0],1)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 2,3) Model building and hyper parameters intialization\n",
        "model = Sequential()\n",
        "model.add(Dense(1,input_shape=(30,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "              ,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#) training the model\n",
        "model.fit(X_train,y_train,epochs=100)\n",
        "\n",
        "\n",
        "#) evaluation of model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "Eqn_uPcmZrs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}